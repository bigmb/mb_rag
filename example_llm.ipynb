{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb2bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mb_rag.basic import ModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05e3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mb_rag.utils.extra import load_env_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c26c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_env_file('./.env');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dc7f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94eeece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm1_openai = ModelFactory(model_type='openai', model_name='gpt-4o')\n",
    "llm2_gemini = ModelFactory(model_type='google', model_name='gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a996afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm1_openai.invoke_query('what is the capital of France?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a18f29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am doing well, thank you for asking! As a large language model, I don't experience emotions or feelings like humans do, but I am functioning optimally and ready to assist you. How can I help you today?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm2_gemini.invoke_query(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac2053c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20514db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image shows a bowl filled with dark granules and several brown eggs placed on top. Some of the eggs are outlined with green squares.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm1_openai.invoke_query('tell me whats there in the image',images=['./examples/output.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12fc1535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a description of what's in the image:\\n\\nThe image shows a white bowl filled with a bed of dark, fine gravel or sand. Scattered within this material are six brown eggs. The eggs are each highlighted with a green box around them. The bowl is sitting on a surface that looks like a metal countertop.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm2_gemini.invoke_query('tell me whats there in the image',images=['./examples/output.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39049a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with pydantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eecdc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d389538",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fact(BaseModel):\n",
    "    statement: str = Field(..., description=\"The statement to be fact-checked\")\n",
    "    reference: str = Field(..., description=\"The reference to the statement\")\n",
    "    funny_score: int = Field(..., description=\"The funny score of the statement\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c001ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using structured model with pydantic schema. So get_content_only is set to False.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fact(statement='Honey never spoils, archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible.', reference=\"National Geographic has reported on this discovery, referencing the longevity of honey's edibility due to its unique chemical composition.\", funny_score=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm1_openai.invoke_query(\"hello tell me a fact\",pydantic_model=fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edfde2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using structured model with pydantic schema. So get_content_only is set to False.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fact(statement='The sky is blue', reference='a scientific paper', funny_score=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm2_gemini.invoke_query(\"hello tell me a fact\",pydantic_model=fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d93e0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class image_desc(BaseModel):\n",
    "    image: str = Field(description=\"Image to describe\")\n",
    "    image_items: list[str] = Field(description=\"List of items in the image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38fbc994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using structured model with pydantic schema. So get_content_only is set to False.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "image_desc(image='A round white container filled with dark, granular, pebble-like material. There are seven brown eggs partly buried in the material. Green squares highlight six of the eggs.', image_items=['White container', 'Dark granular material', 'Seven brown eggs', 'Green squares around eggs'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm1_openai.invoke_query('describe the image?',images=['./examples/output.jpg'],pydantic_model=image_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cc39f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using structured model with pydantic schema. So get_content_only is set to False.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "image_desc(image='describe the image?Here is the original image:', image_items=['eggs'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm2_gemini.invoke_query('describe the image?',images=['./examples/output.jpg'],pydantic_model=image_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b8c1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659f72cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
